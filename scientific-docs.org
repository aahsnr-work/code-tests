#+TITLE: Quantum Harmonic Oscillator: A Masterclass in Computational Physics with Python and Comprehensive Testing
#+AUTHOR: A Complete Guide to Scientific Computing with Test-Driven Development
#+DATE: \today
#+EMAIL: computational.physics@example.com
#+STARTUP: latexpreview inlineimages
#+OPTIONS: toc:3 num:t H:5 ^:{} tags:nil
#+PROPERTY: header-args:python :session qho_master :results output :exports both
#+LATEX_CLASS: article
#+LATEX_HEADER: \usepackage{amsmath,physics,siunitx,booktabs,graphicx,listings,hyperref}
#+LATEX_HEADER: \usepackage[margin=1in]{geometry}

* Document Metadata :noexport:
:PROPERTIES:
:CREATED:  [2025-11-02 Sat]
:CATEGORY: Computational Physics with Testing
:VERSION:  Python 3.13
:PROJECT:  Quantum Harmonic Oscillator with TDD
:TESTING:  pytest, hypothesis, coverage.py
:END:

* Abstract
:PROPERTIES:
:UNNUMBERED: t
:END:

#+begin_abstract
This masterclass integrates quantum mechanics computational physics with modern software engineering best practices. Using the Quantum Harmonic Oscillator (QHO) as our case study, we progress from foundational Python programming through NumPy, SciPy, and visualization, then solve the Schr√∂dinger equation using multiple numerical methods, and finally apply physics-informed neural networks‚Äîall while maintaining comprehensive test coverage, validation, and quality assurance. We emphasize test-driven development (TDD), continuous integration (CI), property-based testing, and performance optimization. Every concept is demonstrated through executable, reproducible, and thoroughly tested code in the Org-mode literate programming environment. By the end, you will have built a production-ready computational physics toolkit with >90% test coverage and industrial-grade quality.
#+end_abstract

* Part I: Scientific Python Ecosystem with Testing Foundations
:PROPERTIES:
:CUSTOM_ID: sec:part-i
:END:

** Introduction: The Quantum Harmonic Oscillator as Our Guide
:PROPERTIES:
:CUSTOM_ID: sec:introduction
:END:

The quantum harmonic oscillator is the most important exactly solvable problem in quantum mechanics, and using Org-mode's literate programming capabilities allows us to create self-contained, executable documentation that combines code, mathematics, and narrative in a single, version-controllable document.

The Hamiltonian is:
$\hat{H} = \frac{\hat{p}^2}{2m} + \frac{1}{2}m\omega^2\hat{x}^2$

Energy eigenvalues:
#+begin_equation
E_n = \hbar\omega\left(n + \frac{1}{2}\right), \quad n = 0, 1, 2, \ldots
#+end_equation

Wavefunctions:
#+begin_equation
\psi_n(x) = \left(\frac{m\omega}{\pi\hbar}\right)^{1/4} \frac{1}{\sqrt{2^n n!}} H_n\left(\sqrt{\frac{m\omega}{\hbar}}x\right) \exp\left(-\frac{m\omega x^2}{2\hbar}\right)
#+end_equation

** Python Programming with Test-Driven Development
:PROPERTIES:
:CUSTOM_ID: sec:python-tdd-foundation
:END:

*** Environment Setup with Testing Infrastructure

#+begin_src jupyter-python
"""
Quantum Harmonic Oscillator Computational Physics Masterclass
Environment setup with testing infrastructure
"""
import numpy as np
import scipy as sp
from scipy import linalg, integrate, special, optimize
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from typing import List, Dict, Tuple, Optional, Union, Any, Callable
from dataclasses import dataclass, field
from functools import wraps, lru_cache
from abc import ABC, abstractmethod
import warnings
import logging

# Testing imports
import pytest
from hypothesis import given, strategies as st, settings
from hypothesis import assume, note
import coverage

warnings.filterwarnings('ignore')

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Plotting configuration
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (10, 6)
plt.rcParams['font.size'] = 11
plt.rcParams['text.usetex'] = False

# Physical constants (atomic units: ‚Ñè = m = œâ = 1)
HBAR = 1.0
MASS = 1.0
OMEGA = 1.0

# Numerical parameters
N_POINTS = 512
X_MAX = 10.0

# Testing parameters
TOLERANCE_ENERGY = 1e-6
TOLERANCE_NORM = 1e-3
TOLERANCE_ORTHOGONAL = 1e-10

np.random.seed(42)

logger.info("‚úì Environment initialized with testing infrastructure!")
logger.info(f"  NumPy version: {np.__version__}")
logger.info(f"  SciPy version: {sp.__version__}")
logger.info(f"  pytest available for testing")
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: [31m---------------------------------------------------------------------------[39m
: [31mModuleNotFoundError[39m                       Traceback (most recent call last)
: [36mCell[39m[36m [39m[32mIn[1][39m[32m, line 19[39m
: [32m     16[39m [38;5;28;01mimport[39;00m[38;5;250m [39m[34;01mlogging[39;00m
: [32m     18[39m [38;5;66;03m# Testing imports[39;00m
: [32m---> [39m[32m19[39m [38;5;28;01mimport[39;00m[38;5;250m [39m[34;01mpytest[39;00m
: [32m     20[39m [38;5;28;01mfrom[39;00m[38;5;250m [39m[34;01mhypothesis[39;00m[38;5;250m [39m[38;5;28;01mimport[39;00m given, strategies [38;5;28;01mas[39;00m st, settings
: [32m     21[39m [38;5;28;01mfrom[39;00m[38;5;250m [39m[34;01mhypothesis[39;00m[38;5;250m [39m[38;5;28;01mimport[39;00m assume, note
:
: [31mModuleNotFoundError[39m: No module named 'pytest'
:END:

*** Custom Exceptions with Validation and Testing

#+begin_src python
"""Custom exceptions for quantum mechanics with comprehensive error handling"""

class QuantumError(Exception):
    """Base exception for quantum mechanics errors"""
    pass

class InvalidQuantumNumberError(QuantumError):
    """Raised when quantum number is invalid"""
    def __init__(self, n, message=None):
        self.n = n
        if message is None:
            message = f"Invalid quantum number: {n}. Must be non-negative integer."
        super().__init__(message)

class NormalizationError(QuantumError):
    """Raised when wavefunction normalization fails"""
    def __init__(self, norm, tolerance=TOLERANCE_NORM):
        self.norm = norm
        self.tolerance = tolerance
        super().__init__(
            f"Wavefunction normalization failed: ‚à´|œà|¬≤ = {norm:.6f} "
            f"(expected 1.0 ¬± {tolerance})"
        )

class ConvergenceError(QuantumError):
    """Raised when numerical method fails to converge"""
    pass

def validate_quantum_number(func):
    """Decorator to validate quantum number n with comprehensive checks"""
    @wraps(func)
    def wrapper(self, n, *args, **kwargs):
        if not isinstance(n, (int, np.integer)):
            raise InvalidQuantumNumberError(
                n, f"Quantum number must be integer, got {type(n).__name__}"
            )
        if n < 0:
            raise InvalidQuantumNumberError(
                n, f"Quantum number must be non-negative, got n={n}"
            )
        if n > 1000:  # Sanity check for extremely high quantum numbers
            logger.warning(
                f"Very high quantum number n={n} requested. "
                "Numerical accuracy may be compromised."
            )
        return func(self, n, *args, **kwargs)
    return wrapper

def validate_normalization(func):
    """Decorator to ensure wavefunction is normalized after computation"""
    @wraps(func)
    def wrapper(self, *args, **kwargs):
        psi = func(self, *args, **kwargs)
        norm = np.trapz(np.abs(psi)**2, self.x_grid)
        if not np.isclose(norm, 1.0, rtol=TOLERANCE_NORM):
            logger.warning(
                f"Wavefunction normalization: ‚à´|œà|¬≤ = {norm:.6f} "
                f"(renormalizing...)"
            )
            psi /= np.sqrt(norm)
        return psi
    return wrapper

logger.info("Custom exceptions and validation decorators defined")
#+end_src

** Test-Driven Development: Unit Testing Fundamentals
:PROPERTIES:
:CUSTOM_ID: sec:testing-fundamentals
:END:

*** Writing Effective Unit Tests with pytest

Following SciPy's testing practices, we use pytest as our testing framework with continuous integration to ensure all tests pass before code is merged, maintaining over 13,000 unit tests in production libraries.

#+begin_src python
"""
Comprehensive unit testing framework for quantum mechanics
This demonstrates best practices for scientific computing tests
"""

class TestQuantumMechanicsFoundations:
    """Test suite for fundamental quantum mechanics properties"""

    def test_uncertainty_principle(self):
        """Test Heisenberg uncertainty principle: Œîx¬∑Œîp ‚â• ‚Ñè/2"""
        # This is a fundamental requirement all quantum states must satisfy
        x = np.linspace(-10, 10, 1000)
        dx = x[1] - x[0]

        # Gaussian wave packet
        sigma_x = 1.0
        psi = np.exp(-x**2 / (2 * sigma_x**2))
        psi /= np.sqrt(np.trapz(np.abs(psi)**2, x))

        # Calculate position uncertainty
        x_mean = np.trapz(np.abs(psi)**2 * x, x)
        x2_mean = np.trapz(np.abs(psi)**2 * x**2, x)
        delta_x = np.sqrt(x2_mean - x_mean**2)

        # Calculate momentum uncertainty via Fourier transform
        psi_k = np.fft.fft(psi)
        k = 2 * np.pi * np.fft.fftfreq(len(x), dx)
        k_sorted = np.fft.fftshift(k)
        psi_k_sorted = np.fft.fftshift(psi_k)

        p = HBAR * k_sorted
        prob_p = np.abs(psi_k_sorted)**2
        prob_p /= np.trapz(prob_p, p)

        p_mean = np.trapz(prob_p * p, p)
        p2_mean = np.trapz(prob_p * p**2, p)
        delta_p = np.sqrt(np.abs(p2_mean - p_mean**2))

        uncertainty_product = delta_x * delta_p

        assert uncertainty_product >= HBAR / 2 * 0.99, \
            f"Uncertainty principle violated: Œîx¬∑Œîp = {uncertainty_product:.6f}"

        logger.info(f"‚úì Uncertainty principle: Œîx¬∑Œîp = {uncertainty_product:.6f}‚Ñè")

    def test_probability_conservation(self):
        """Test that probability is conserved: ‚à´|œà|¬≤ dx = 1"""
        x = np.linspace(-10, 10, 1000)

        # Test multiple wavefunctions
        test_functions = [
            np.exp(-x**2),  # Gaussian
            np.sin(x) * np.exp(-x**2/4),  # Modulated Gaussian
            (1 + x**2) * np.exp(-x**2)  # Polynomial times Gaussian
        ]

        for i, psi_unnormalized in enumerate(test_functions):
            # Normalize
            norm = np.sqrt(np.trapz(np.abs(psi_unnormalized)**2, x))
            psi = psi_unnormalized / norm

            # Check normalization
            total_prob = np.trapz(np.abs(psi)**2, x)
            assert np.isclose(total_prob, 1.0, rtol=1e-6), \
                f"Test function {i}: ‚à´|œà|¬≤ = {total_prob:.10f} ‚â† 1"

        logger.info("‚úì Probability conservation verified for multiple functions")

    @pytest.mark.parametrize("n", [0, 1, 2, 5, 10])
    def test_quantum_number_validity(self, n):
        """Test that quantum numbers are properly validated"""
        # Valid quantum numbers should not raise errors
        assert n >= 0
        assert isinstance(n, int)

    def test_invalid_quantum_numbers(self):
        """Test that invalid quantum numbers raise appropriate errors"""
        invalid_numbers = [-1, -5, 3.5, "two", None]

        for invalid_n in invalid_numbers:
            with pytest.raises((InvalidQuantumNumberError, TypeError)):
                if not isinstance(invalid_n, int) or invalid_n < 0:
                    raise InvalidQuantumNumberError(invalid_n)

logger.info("Unit test framework defined")
logger.info("Run tests with: pytest test_qho.py -v")
#+end_src

*** Property-Based Testing with Hypothesis

Property-based testing generates random test cases to verify that properties hold for all inputs, catching edge cases that manual testing might miss.

#+begin_src python
"""
Property-based testing for quantum mechanics
Using Hypothesis to test mathematical properties
"""

@given(
    sigma=st.floats(min_value=0.1, max_value=5.0),
    x0=st.floats(min_value=-5.0, max_value=5.0)
)
@settings(max_examples=50, deadline=None)
def test_gaussian_wavepacket_properties(sigma, x0):
    """Test that Gaussian wave packets satisfy quantum mechanical properties"""
    x = np.linspace(-20, 20, 1000)
    dx = x[1] - x[0]

    # Create Gaussian wave packet
    psi = np.exp(-(x - x0)**2 / (2 * sigma**2))

    # Normalize
    norm = np.sqrt(np.trapz(np.abs(psi)**2, x))
    assume(norm > 0.01)  # Skip if norm too small
    psi_normalized = psi / norm

    # Property 1: Normalization
    total_prob = np.trapz(np.abs(psi_normalized)**2, x)
    assert np.isclose(total_prob, 1.0, rtol=1e-3), \
        f"Normalization failed: ‚à´|œà|¬≤ = {total_prob}"

    # Property 2: Position expectation value near x0
    x_mean = np.trapz(np.abs(psi_normalized)**2 * x, x)
    assert np.abs(x_mean - x0) < sigma, \
        f"<x> = {x_mean:.3f} too far from x0 = {x0:.3f}"

    # Property 3: Minimum uncertainty product for Gaussian
    x2_mean = np.trapz(np.abs(psi_normalized)**2 * x**2, x)
    delta_x = np.sqrt(x2_mean - x_mean**2)

    # For Gaussian, Œîx ‚âà œÉ
    assert np.isclose(delta_x, sigma, rtol=0.1), \
        f"Œîx = {delta_x:.3f} doesn't match œÉ = {sigma:.3f}"

@given(
    n=st.integers(min_value=0, max_value=20),
    grid_size=st.integers(min_value=100, max_value=500)
)
@settings(max_examples=30, deadline=None)
def test_hermite_polynomial_orthogonality(n, grid_size):
    """Test Hermite polynomial orthogonality"""
    x = np.linspace(-5, 5, grid_size)
    weight = np.exp(-x**2)

    # Generate two adjacent Hermite polynomials
    H_n = sp.special.hermite(n, monic=False)(x)
    H_n1 = sp.special.hermite(n+1, monic=False)(x)

    # Calculate overlap
    overlap = np.trapz(H_n * H_n1 * weight, x)

    # Should be orthogonal
    assert np.abs(overlap) < 1.0, \
        f"Hermite H_{n} and H_{n+1} not orthogonal: overlap = {overlap}"

logger.info("Property-based tests defined")
logger.info("Hypothesis generates random test cases automatically")
#+end_src

** Object-Oriented Design with Comprehensive Testing
:PROPERTIES:
:CUSTOM_ID: sec:oop-testing
:END:

*** Quantum System Hierarchy with Test Integration

#+begin_src python :tangle qho_toolkit.py
"""
Abstract base class for quantum systems with built-in validation
"""

class QuantumSystem(ABC):
    """
    Abstract base class for one-dimensional quantum systems.

    All concrete quantum systems must implement:
    - potential(x): Return V(x)
    - analytical_energy(n): Return analytical energy (if known)
    - analytical_wavefunction(x, n): Return analytical œà_n(x) (if known)

    Includes comprehensive validation and testing utilities.
    """

    def __init__(self, mass: float = MASS, x_grid: Optional[np.ndarray] = None):
        self.mass = mass
        if x_grid is None:
            self.x_grid = np.linspace(-X_MAX, X_MAX, N_POINTS)
        else:
            self.x_grid = x_grid
        self.dx = self.x_grid[1] - self.x_grid[0]

        # Validation
        self._validate_initialization()

    def _validate_initialization(self):
        """Validate system initialization parameters"""
        if self.mass <= 0:
            raise ValueError(f"Mass must be positive, got {self.mass}")
        if len(self.x_grid) < 10:
            raise ValueError(f"Grid too coarse: {len(self.x_grid)} points")
        if not np.all(np.diff(self.x_grid) > 0):
            raise ValueError("Grid must be monotonically increasing")

    @abstractmethod
    def potential(self, x: np.ndarray) -> np.ndarray:
        """Return potential energy V(x)"""
        pass

    def get_hamiltonian_matrix(self) -> np.ndarray:
        """
        Construct Hamiltonian matrix using finite difference method.

        Returns:
            H: Hamiltonian matrix (N √ó N)

        Raises:
            ValueError: If grid is too coarse for accurate representation
        """
        N = len(self.x_grid)
        H = np.zeros((N, N))

        # Kinetic energy: -‚Ñè¬≤/(2m) d¬≤/dx¬≤
        kinetic_coeff = -HBAR**2 / (2 * self.mass * self.dx**2)

        for i in range(N):
            H[i, i] = -2 * kinetic_coeff + self.potential(self.x_grid[i])
            if i > 0:
                H[i, i-1] = kinetic_coeff
            if i < N - 1:
                H[i, i+1] = kinetic_coeff

        # Validate Hamiltonian is Hermitian
        if not np.allclose(H, H.T.conj(), atol=1e-10):
            raise ValueError("Hamiltonian is not Hermitian")

        return H

    def solve_eigenvalue_problem(
        self, n_states: int = 10, validate: bool = True
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        Solve time-independent Schr√∂dinger equation.

        Args:
            n_states: Number of eigenstates to compute
            validate: Whether to validate results

        Returns:
            energies: Array of energy eigenvalues
            wavefunctions: Array of wavefunctions (n_states √ó N_POINTS)

        Raises:
            ConvergenceError: If eigenvalue solver fails
            NormalizationError: If normalization fails
        """
        H = self.get_hamiltonian_matrix()

        try:
            eigenvalues, eigenvectors = linalg.eigh(H)
        except linalg.LinAlgError as e:
            raise ConvergenceError(f"Eigenvalue solver failed: {e}")

        # Sort by energy
        idx = np.argsort(eigenvalues)
        energies = eigenvalues[idx[:n_states]]
        wavefunctions = eigenvectors[:, idx[:n_states]].T

        # Normalize wavefunctions
        for i in range(n_states):
            norm = np.sqrt(np.trapz(wavefunctions[i]**2, self.x_grid))
            if norm < 1e-10:
                raise NormalizationError(norm)
            wavefunctions[i] /= norm

        # Validation
        if validate:
            self._validate_eigensolution(energies, wavefunctions)

        return energies, wavefunctions

    def _validate_eigensolution(
        self, energies: np.ndarray, wavefunctions: np.ndarray
    ):
        """Validate eigenvalue solution"""
        # Check normalization
        for i, psi in enumerate(wavefunctions):
            norm = np.trapz(psi**2, self.x_grid)
            if not np.isclose(norm, 1.0, rtol=TOLERANCE_NORM):
                raise NormalizationError(norm)

        # Check orthogonality
        for i in range(len(wavefunctions)):
            for j in range(i+1, min(i+5, len(wavefunctions))):
                overlap = np.trapz(
                    wavefunctions[i] * wavefunctions[j],
                    self.x_grid
                )
                if not np.isclose(overlap, 0.0, atol=TOLERANCE_ORTHOGONAL):
                    logger.warning(
                        f"States {i} and {j} not perfectly orthogonal: "
                        f"<i|j> = {overlap:.2e}"
                    )

        # Check energy ordering
        if not np.all(np.diff(energies) >= 0):
            raise ValueError("Energy eigenvalues not properly ordered")

        logger.debug(f"‚úì Validated {len(energies)} eigenstates")

    @abstractmethod
    def analytical_energy(self, n: int) -> float:
        """Return analytical energy for level n (if known)"""
        pass

    @abstractmethod
    def analytical_wavefunction(self, x: np.ndarray, n: int) -> np.ndarray:
        """Return analytical wavefunction œà_n(x) (if known)"""
        pass

logger.info("QuantumSystem base class with validation defined")
#+end_src

*** Quantum Harmonic Oscillator with Tests

#+begin_src python :tangle qho_toolkit.py
"""
Concrete implementation of quantum harmonic oscillator with testing
"""

class QuantumHarmonicOscillator(QuantumSystem):
    """
    Quantum harmonic oscillator: V(x) = ¬Ωmœâ¬≤x¬≤

    This class includes both numerical and analytical solutions,
    with comprehensive validation and testing capabilities.
    """

    def __init__(
        self,
        mass: float = MASS,
        omega: float = OMEGA,
        x_grid: Optional[np.ndarray] = None
    ):
        super().__init__(mass, x_grid)
        self.omega = omega
        self.alpha = np.sqrt(mass * omega / HBAR)

        if self.omega <= 0:
            raise ValueError(f"Frequency must be positive, got {omega}")

    def potential(self, x: np.ndarray) -> np.ndarray:
        """Harmonic potential V(x) = ¬Ωmœâ¬≤x¬≤"""
        return 0.5 * self.mass * self.omega**2 * x**2

    @validate_quantum_number
    def analytical_energy(self, n: int) -> float:
        """
        Exact energy eigenvalue: E_n = ‚Ñèœâ(n + ¬Ω)

        This is the ground truth for validating numerical methods.
        """
        return HBAR * self.omega * (n + 0.5)

    @validate_quantum_number
    @validate_normalization
    def analytical_wavefunction(self, x: np.ndarray, n: int) -> np.ndarray:
        """
        Exact wavefunction using Hermite polynomials.

        œà_n(x) = (Œ±/œÄ)^(1/4) ¬∑ 1/‚àö(2^n n!) ¬∑ H_n(Œ±x) ¬∑ exp(-Œ±¬≤x¬≤/2)

        Automatically normalized via decorator.
        """
        # Normalization constant
        norm = (self.alpha / np.pi)**0.25 / \
               np.sqrt(2**n * sp.special.factorial(n))

        # Hermite polynomial
        xi = self.alpha * x
        hermite = sp.special.hermite(n, monic=False)

        # Complete wavefunction
        psi = norm * hermite(xi) * np.exp(-xi**2 / 2)

        return psi

    def verify_analytical_properties(self, n_max: int = 10) -> Dict[str, Any]:
        """
        Verify analytical solution satisfies all quantum mechanical properties.

        Returns:
            Dictionary with verification results
        """
        results = {
            'normalization': [],
            'orthogonality': [],
            'energy_spacing': [],
            'expectation_values': {}
        }

        # Test normalization
        for n in range(n_max):
            psi = self.analytical_wavefunction(self.x_grid, n)
            norm = np.trapz(psi**2, self.x_grid)
            results['normalization'].append({
                'n': n,
                'norm': norm,
                'passed': np.isclose(norm, 1.0, rtol=TOLERANCE_NORM)
            })

        # Test orthogonality
        for n1 in range(min(5, n_max)):
            for n2 in range(n1+1, min(5, n_max)):
                psi1 = self.analytical_wavefunction(self.x_grid, n1)
                psi2 = self.analytical_wavefunction(self.x_grid, n2)
                overlap = np.trapz(psi1 * psi2, self.x_grid)
                results['orthogonality'].append({
                    'n1': n1, 'n2': n2,
                    'overlap': overlap,
                    'passed': np.abs(overlap) < TOLERANCE_ORTHOGONAL
                })

        # Test energy spacing
        for n in range(n_max - 1):
            E_n = self.analytical_energy(n)
            E_n1 = self.analytical_energy(n+1)
            spacing = E_n1 - E_n
            expected_spacing = HBAR * self.omega
            results['energy_spacing'].append({
                'n': n,
                'spacing': spacing,
                'expected': expected_spacing,
                'passed': np.isclose(spacing, expected_spacing, rtol=1e-10)
            })

        return results

    def __call__(self, x: np.ndarray, n: int) -> np.ndarray:
        """Make callable: qho(x, n) returns œà_n(x)"""
        return self.analytical_wavefunction(x, n)

    def __repr__(self) -> str:
        return (
            f"QuantumHarmonicOscillator(mass={self.mass}, "
            f"omega={self.omega}, N={len(self.x_grid)})"
        )

# Create and test instance
qho = QuantumHarmonicOscillator()
logger.info(f"Created: {qho}")
logger.info(f"Ground state: E_0 = {qho.analytical_energy(0):.6f}")

# Verify analytical properties
verification = qho.verify_analytical_properties(n_max=5)
all_norm_passed = all(r['passed'] for r in verification['normalization'])
all_orth_passed = all(r['passed'] for r in verification['orthogonality'])

if all_norm_passed and all_orth_passed:
    logger.info("‚úì All analytical properties verified")
else:
    logger.warning("‚ö† Some analytical properties failed verification")
#+end_src

** Comprehensive Testing Suite for QHO
:PROPERTIES:
:CUSTOM_ID: sec:comprehensive-testing
:END:

*** Complete Unit Test Suite

#+begin_src python
"""
Comprehensive test suite for Quantum Harmonic Oscillator
Following best practices from scientific computing literature
"""

class TestQuantumHarmonicOscillator:
    """Complete test suite for QHO implementation"""

    @pytest.fixture
    def qho(self):
        """Fixture providing QHO instance"""
        return QuantumHarmonicOscillator()

    @pytest.fixture
    def qho_fine_grid(self):
        """Fixture with fine grid for high-accuracy tests"""
        x_grid = np.linspace(-X_MAX, X_MAX, 1024)
        return QuantumHarmonicOscillator(x_grid=x_grid)

    # === Energy Tests ===
    @pytest.mark.parametrize("n,expected_ratio", [
        (0, 0.5), (1, 1.5), (2, 2.5), (5, 5.5), (10, 10.5)
    ])
    def test_energy_eigenvalues(self, qho, n, expected_ratio):
        """Test analytical energy eigenvalues"""
        E_n = qho.analytical_energy(n)
        expected = expected_ratio * HBAR * qho.omega
        assert np.isclose(E_n, expected, rtol=1e-10), \
            f"E_{n} = {E_n}, expected {expected}"

    def test_energy_spacing_constant(self, qho):
        """Test that energy level spacing is constant (‚Ñèœâ)"""
        spacings = []
        for n in range(10):
            E_n = qho.analytical_energy(n)
            E_n1 = qho.analytical_energy(n+1)
            spacings.append(E_n1 - E_n)

        expected_spacing = HBAR * qho.omega
        for i, spacing in enumerate(spacings):
            assert np.isclose(spacing, expected_spacing, rtol=1e-10), \
                f"Spacing {i}: {spacing} ‚â† {expected_spacing}"

    # === Wavefunction Tests ===
    def test_wavefunction_normalization(self, qho):
        """Test wavefunction normalization for multiple states"""
        for n in range(10):
            psi = qho.analytical_wavefunction(qho.x_grid, n)
            norm = np.trapz(psi**2, qho.x_grid)
            assert np.isclose(norm, 1.0, rtol=TOLERANCE_NORM), \
                f"n={n}: ‚à´|œà|¬≤ = {norm:.10f}"

    def test_wavefunction_orthogonality(self, qho_fine_grid):
        """Test orthogonality between different states"""
        n_states = 10
        wavefunctions = []

        for n in range(n_states):
            psi = qho_fine_grid.analytical_wavefunction(
                qho_fine_grid.x_grid, n
            )
            wavefunctions.append(psi)

        # Check all pairs
        for i in range(n_states):
            for j in range(i+1, n_states):
                overlap = np.trapz(
                    wavefunctions[i] * wavefunctions[j],
                    qho_fine_grid.x_grid
                )
                assert np.abs(overlap) < TOLERANCE_ORTHOGONAL, \
                    f"<{i}|{j}> = {overlap:.2e} (not orthogonal)"

    def test_ground_state_no_nodes(self, qho):
        """Test that ground state has no nodes (zeros)"""
        psi_0 = qho.analytical_wavefunction(qho.x_grid, 0)
        # Ground state should be everywhere positive (or negative)
        assert np.all(psi_0 > 0) or np.all(psi_0 < 0), \
            "Ground state has nodes"

    @pytest.mark.parametrize("n", range(10))
    def test_wavefunction_node_count(self, qho, n):
        """Test that œà_n has exactly n nodes"""
        psi = qho.analytical_wavefunction(qho.x_grid, n)

        # Count sign changes (nodes)
        sign_changes = np.sum(np.diff(np.sign(psi)) != 0)

        # Allow ¬±1 due to numerical discretization
        assert abs(sign_changes - n) <= 1, \
            f"œà_{n} has {sign_changes} nodes, expected {n}"

    # === Numerical vs Analytical Tests ===
    def test_numerical_vs_analytical_energies(self, qho):
        """Compare numerical and analytical energy eigenvalues"""
        n_states = 10
        energies_num, _ = qho.solve_eigenvalue_problem(n_states)

        for n in range(n_states):
            E_analytical = qho.analytical_energy(n)
            E_numerical = energies_num[n]
            rel_error = abs(E_numerical - E_analytical) / E_analytical

            assert rel_error < 1e-4, \
                f"n={n}: Numerical {E_numerical:.6f} vs " \
                f"Analytical {E_analytical:.6f} (error: {rel_error:.2e})"

    def test_numerical_vs_analytical_wavefunctions(self, qho):
        """Compare numerical and analytical wavefunctions"""
        n_states = 5
        _, wavefunctions_num = qho.solve_eigenvalue_problem(n_states)

        for n in range(n_states):
            psi_numerical = wavefunctions_num[n]
            psi_analytical = qho.analytical_wavefunction(qho.x_grid, n)

            # Fix relative phase
            phase = np.sign(psi_numerical[len(psi_numerical)//2]) * \
                    np.sign(psi_analytical[len(psi_analytical)//2])
            psi_numerical *= phase

            # Calculate overlap
            overlap = np.trapz(
                psi_numerical * psi_analytical,
                qho.x_grid
            )

            assert overlap > 0.999, \
                f"n={n}: Overlap = {overlap:.6f} (insufficient agreement)"

    # === Physical Properties Tests ===
    def test_expectation_position_ground_state(self, qho):
        """Test <x> = 0 for ground state by symmetry"""
        psi_0 = qho.analytical_wavefunction(qho.x_grid, 0)
        x_mean = np.trapz(psi_0**2 * qho.x_grid, qho.x_grid)
        assert np.abs(x_mean) < 1e-10, f"<x> = {x_mean} ‚â† 0"

    def test_expectation_x_squared(self, qho):
        """Test <x¬≤> for ground state: <x¬≤> = 1/(2Œ±¬≤)"""
        psi_0 = qho.analytical_wavefunction(qho.x_grid, 0)
        x2_mean = np.trapz(psi_0**2 * qho.x_grid**2, qho.x_grid)
        expected = 1 / (2 * qho.alpha**2)
        assert np.isclose(x2_mean, expected, rtol=1e-3), \
            f"<x¬≤> = {x2_mean:.6f}, expected {expected:.6f}"

    def test_virial_theorem(self, qho):
        """Test virial theorem: <T> = <V> for harmonic oscillator"""
        for n in range(5):
            psi = qho.analytical_wavefunction(qho.x_grid, n)

            # Kinetic energy: <T> = -‚Ñè¬≤/2m ‚à´ œà d¬≤œà/dx¬≤
            psi_xx = np.gradient(np.gradient(psi, qho.dx), qho.dx)
            T_mean = -HBAR**2 / (2 * qho.mass) * \
                     np.trapz(psi * psi_xx, qho.x_grid)

            # Potential energy: <V> = ‚à´ œà¬≤ V(x)
            V_mean = np.trapz(psi**2 * qho.potential(qho.x_grid), qho.x_grid)

            assert np.isclose(T_mean, V_mean, rtol=1e-2), \
                f"n={n}: <T>={T_mean:.6f}, <V>={V_mean:.6f} (virial violated)"

    # === Edge Case Tests ===
    def test_invalid_quantum_numbers(self, qho):
        """Test rejection of invalid quantum numbers"""
        invalid_numbers = [-1, -5, 3.5, "two", None, float('inf')]

        for invalid_n in invalid_numbers:
            with pytest.raises((InvalidQuantumNumberError, TypeError)):
                qho.analytical_energy(invalid_n)

    def test_extreme_quantum_numbers(self, qho):
        """Test behavior with very high quantum numbers"""
        # High n should work but may have accuracy issues
        n_high = 100
        try:
            E_high = qho.analytical_energy(n_high)
            expected = HBAR * qho.omega * (n_high + 0.5)
            assert np.isclose(E_high, expected, rtol=1e-8)
        except (OverflowError, InvalidQuantumNumberError):
            pytest.skip("System cannot handle n=100")

    def test_grid_independence(self):
        """Test that results are independent of grid choice"""
        grids = [
            np.linspace(-10, 10, 256),
            np.linspace(-10, 10, 512),
            np.linspace(-10, 10, 1024),
        ]

        energies_list = []
        for grid in grids:
            qho_test = QuantumHarmonicOscillator(x_grid=grid)
            E, _ = qho_test.solve_eigenvalue_problem(n_states=5)
            energies_list.append(E)

        # All grids should give similar results
        for i in range(len(energies_list)-1):
            max_diff = np.max(np.abs(
                energies_list[i] - energies_list[i+1]
            ))
            assert max_diff < 1e-3, \
                f"Grid {i} vs {i+1}: max diff = {max_diff}"

    # === Performance Tests ===
    @pytest.mark.slow
    def test_performance_eigenvalue_solver(self, benchmark, qho):
        """Benchmark eigenvalue solver performance"""
        def solve():
            return qho.solve_eigenvalue_problem(n_states=20)

        result = benchmark(solve)
        # Should complete in reasonable time
        assert benchmark.stats.stats.mean < 1.0  # 1 second

logger.info("Comprehensive test suite defined")
logger.info("‚úì Tests cover: energy, wavefunctions, numerical accuracy")
logger.info("‚úì Tests include: edge cases, physical properties, performance")
#+end_src

*** Integration Tests for Complete Workflows

#+begin_src python
"""
Integration tests for complete computational physics workflows
"""

class TestCompleteWorkflows:
    """Test complete analysis workflows"""

    def test_complete_eigenvalue_analysis(self):
        """Test complete workflow: create system ‚Üí solve ‚Üí validate"""
        # Setup
        qho = QuantumHarmonicOscillator()

        # Solve
        energies, wavefunctions = qho.solve_eigenvalue_problem(n_states=10)

        # Validate results
        assert len(energies) == 10
        assert wavefunctions.shape == (10, len(qho.x_grid))

        # Check all energies are positive
        assert np.all(energies > 0)

        # Check energy ordering
        assert np.all(np.diff(energies) > 0)

        # Verify against analytical
        for n in range(10):
            E_analytical = qho.analytical_energy(n)
            rel_error = abs(energies[n] - E_analytical) / E_analytical
            assert rel_error < 1e-3

    def test_wavefunction_evolution_preparation(self):
        """Test preparing initial state for time evolution"""
        qho = QuantumHarmonicOscillator()

        # Create Gaussian wave packet
        x0 = 2.0
        sigma = 1.0
        psi_0 = np.exp(-(qho.x_grid - x0)**2 / (2*sigma**2))

        # Normalize
        norm = np.sqrt(np.trapz(np.abs(psi_0)**2, qho.x_grid))
        psi_0 /= norm

        # Verify normalization
        final_norm = np.trapz(np.abs(psi_0)**2, qho.x_grid)
        assert np.isclose(final_norm, 1.0, rtol=1e-6)

        # Check it's properly localized
        x_mean = np.trapz(np.abs(psi_0)**2 * qho.x_grid, qho.x_grid)
        assert np.abs(x_mean - x0) < 0.1

    def test_convergence_analysis_workflow(self):
        """Test grid convergence analysis workflow"""
        grid_sizes = [64, 128, 256, 512]
        ground_energies = []

        for N in grid_sizes:
            x_grid = np.linspace(-X_MAX, X_MAX, N)
            qho_test = QuantumHarmonicOscillator(x_grid=x_grid)
            E, _ = qho_test.solve_eigenvalue_problem(n_states=1)
            ground_energies.append(E[0])

        # Check convergence: errors should decrease with grid size
        E_analytical = HBAR * OMEGA * 0.5
        errors = [abs(E - E_analytical) for E in ground_energies]

        # Errors should generally decrease
        for i in range(len(errors)-1):
            # Allow some numerical noise
            assert errors[i+1] <= errors[i] * 1.1

logger.info("Integration tests defined")
#+end_src

** Test Coverage and Continuous Integration
:PROPERTIES:
:CUSTOM_ID: sec:coverage-ci
:END:

*** Measuring Test Coverage

#+begin_src python
"""
Test coverage measurement and reporting
Following industry best practices
"""

def measure_coverage():
    """
    Measure test coverage for QHO module.

    Best practices:
    - Aim for >90% coverage
    - Focus on critical paths
    - Don't obsess over 100%
    """
    print("Test Coverage Analysis")
    print("=" * 60)
    print("\nTo measure coverage, run:")
    print("  pytest --cov=qho_toolkit --cov-report=html")
    print("  pytest --cov=qho_toolkit --cov-report=term-missing")
    print("\nCoverage goals:")
    print("  ‚úì Statement coverage: >90%")
    print("  ‚úì Branch coverage: >85%")
    print("  ‚úì Function coverage: >95%")
    print("\nCritical components requiring 100% coverage:")
    print("  - Input validation")
    print("  - Error handling")
    print("  - Normalization checks")
    print("  - Physical property verification")
    print("\nComponents where <90% is acceptable:")
    print("  - Visualization code")
    print("  - Logging statements")
    print("  - Deprecated functions")

measure_coverage()
#+end_src

*** Continuous Integration Configuration

#+begin_src python
"""
Continuous Integration best practices for scientific computing
"""

ci_config = """
# .github/workflows/tests.yml
name: Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        python-version: ['3.10', '3.11', '3.12', '3.13']

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install dependencies
      run: |
        pip install -e .
        pip install pytest pytest-cov hypothesis

    - name: Run tests
      run: |
        pytest --cov=qho_toolkit --cov-report=xml

    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
"""

print("Continuous Integration Setup")
print("=" * 60)
print(ci_config)
print("\nBest Practices:")
print("  ‚úì Test on multiple OS (Linux, macOS, Windows)")
print("  ‚úì Test on multiple Python versions")
print("  ‚úì Run full test suite on every commit")
print("  ‚úì Measure and track coverage over time")
print("  ‚úì Fail CI if coverage drops")
print("  ‚úì Run performance benchmarks")
#+end_src

* Part II: Advanced Testing and Quality Assurance

** Performance Testing and Optimization
:PROPERTIES:
:CUSTOM_ID: sec:performance-testing
:END:

*** Benchmarking with pytest-benchmark

#+begin_src python
"""
Performance testing and benchmarking
"""

class TestPerformance:
    """Performance benchmarks for critical code paths"""

    def test_benchmark_wavefunction_computation(self, benchmark, qho):
        """Benchmark analytical wavefunction computation"""
        def compute_wavefunction():
            return qho.analytical_wavefunction(qho.x_grid, 5)

        result = benchmark(compute_wavefunction)
        assert result is not None

    def test_benchmark_eigenvalue_solver(self, benchmark, qho):
        """Benchmark numerical eigenvalue solver"""
        def solve_eigen():
            return qho.solve_eigenvalue_problem(n_states=10)

        result = benchmark(solve_eigen)
        energies, wavefunctions = result
        assert len(energies) == 10

    def test_performance_scaling(self):
        """Test performance scaling with system size"""
        import time

        sizes = [64, 128, 256, 512]
        times = []

        for N in sizes:
            x_grid = np.linspace(-X_MAX, X_MAX, N)
            qho_test = QuantumHarmonicOscillator(x_grid=x_grid)

            start = time.time()
            qho_test.solve_eigenvalue_problem(n_states=10)
            elapsed = time.time() - start

            times.append(elapsed)

        # Log results
        for N, t in zip(sizes, times):
            logger.info(f"N={N}: {t:.4f}s")

        # Check scaling is reasonable (should be approximately O(N¬≤))
        # Time should roughly quadruple when N doubles
        for i in range(len(times)-1):
            ratio = times[i+1] / times[i]
            assert 2 < ratio < 8, f"Unexpected scaling: {ratio:.2f}x"

logger.info("Performance tests defined")
#+end_src

*** Profiling and Optimization

#+begin_src python
"""
Code profiling for optimization
"""

import cProfile
import pstats
from pstats import SortKey

def profile_eigenvalue_solver():
    """Profile eigenvalue solver to find bottlenecks"""
    qho = QuantumHarmonicOscillator()

    profiler = cProfile.Profile()
    profiler.enable()

    # Run multiple times for better statistics
    for _ in range(10):
        qho.solve_eigenvalue_problem(n_states=20)

    profiler.disable()

    # Print statistics
    stats = pstats.Stats(profiler)
    stats.strip_dirs()
    stats.sort_stats(SortKey.CUMULATIVE)

    print("\nProfiling Results (Top 10 functions):")
    print("=" * 80)
    stats.print_stats(10)

    print("\nOptimization Opportunities:")
    print("  1. Look for functions called many times")
    print("  2. Identify expensive operations")
    print("  3. Consider vectorization with NumPy")
    print("  4. Use @lru_cache for repeated calculations")
    print("  5. Consider Numba JIT for hot loops")

logger.info("Profiling tools available")
logger.info("Run: profile_eigenvalue_solver() for analysis")
#+end_src

** Regression Testing and Data-Driven Tests
:PROPERTIES:
:CUSTOM_ID: sec:regression-testing
:END:

*** Regression Test Framework

#+begin_src python
"""
Regression testing: ensure fixes don't break existing functionality
"""

import json
from pathlib import Path

class RegressionTestData:
    """Manage regression test data"""

    def __init__(self, data_dir: str = "./test_data"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)

    def save_reference(self, test_name: str, data: Dict[str, Any]):
        """Save reference data for regression testing"""
        file_path = self.data_dir / f"{test_name}.json"

        # Convert numpy arrays to lists for JSON serialization
        serializable_data = {}
        for key, value in data.items():
            if isinstance(value, np.ndarray):
                serializable_data[key] = value.tolist()
            else:
                serializable_data[key] = value

        with open(file_path, 'w') as f:
            json.dump(serializable_data, f, indent=2)

        logger.info(f"Saved reference data: {test_name}")

    def load_reference(self, test_name: str) -> Dict[str, Any]:
        """Load reference data for comparison"""
        file_path = self.data_dir / f"{test_name}.json"

        if not file_path.exists():
            raise FileNotFoundError(f"Reference data not found: {test_name}")

        with open(file_path, 'r') as f:
            data = json.load(f)

        # Convert lists back to numpy arrays
        for key, value in data.items():
            if isinstance(value, list):
                data[key] = np.array(value)

        return data

class TestRegression:
    """Regression tests to prevent breaking changes"""

    @pytest.fixture
    def regression_data(self):
        """Fixture for regression test data"""
        return RegressionTestData()

    def test_ground_state_energy_regression(self, qho, regression_data):
        """Ensure ground state energy hasn't changed"""
        E_0 = qho.analytical_energy(0)

        reference = {
            'energy': float(E_0),
            'mass': qho.mass,
            'omega': qho.omega
        }

        # Uncomment to save new reference:
        # regression_data.save_reference('ground_state_energy', reference)

        # Load and compare
        try:
            ref_data = regression_data.load_reference('ground_state_energy')
            assert np.isclose(E_0, ref_data['energy'], rtol=1e-10), \
                f"Ground state energy changed: {E_0} vs {ref_data['energy']}"
        except FileNotFoundError:
            pytest.skip("No reference data available")

    def test_wavefunction_shape_regression(self, qho):
        """Ensure wavefunction output shape hasn't changed"""
        psi_0 = qho.analytical_wavefunction(qho.x_grid, 0)

        # Shape should match grid
        assert psi_0.shape == qho.x_grid.shape

        # Should be 1D array
        assert psi_0.ndim == 1

        # Should have expected length
        assert len(psi_0) == N_POINTS

logger.info("Regression testing framework defined")
#+end_src

*** Data-Driven Testing with Parametrization

#+begin_src python
"""
Data-driven testing: test with many parameter combinations
"""

# Test data for parametrized tests
ENERGY_TEST_DATA = [
    # (n, expected_ratio, tolerance)
    (0, 0.5, 1e-10),
    (1, 1.5, 1e-10),
    (2, 2.5, 1e-10),
    (5, 5.5, 1e-10),
    (10, 10.5, 1e-10),
    (20, 20.5, 1e-10),
    (50, 50.5, 1e-10),
]

SYSTEM_PARAMETERS = [
    # (mass, omega, n_points)
    (1.0, 1.0, 256),
    (2.0, 1.0, 256),
    (1.0, 2.0, 256),
    (0.5, 0.5, 512),
    (1.5, 1.5, 512),
]

class TestDataDriven:
    """Data-driven tests with multiple parameter sets"""

    @pytest.mark.parametrize("n,expected_ratio,tol", ENERGY_TEST_DATA)
    def test_energy_parametrized(self, qho, n, expected_ratio, tol):
        """Test energy for multiple quantum numbers"""
        E_n = qho.analytical_energy(n)
        expected = expected_ratio * HBAR * qho.omega
        assert np.isclose(E_n, expected, rtol=tol)

    @pytest.mark.parametrize("mass,omega,n_points", SYSTEM_PARAMETERS)
    def test_different_system_parameters(self, mass, omega, n_points):
        """Test QHO with various physical parameters"""
        x_grid = np.linspace(-X_MAX, X_MAX, n_points)
        qho_test = QuantumHarmonicOscillator(
            mass=mass, omega=omega, x_grid=x_grid
        )

        # Solve and validate
        E, psi = qho_test.solve_eigenvalue_problem(n_states=5)

        # Basic checks
        assert len(E) == 5
        assert np.all(E > 0)
        assert np.all(np.diff(E) > 0)

        # Check against analytical
        for n in range(5):
            E_analytical = HBAR * omega * (n + 0.5)
            rel_error = abs(E[n] - E_analytical) / E_analytical
            assert rel_error < 1e-3

logger.info("Data-driven tests with parametrization defined")
#+end_src

** Mutation Testing for Test Quality
:PROPERTIES:
:CUSTOM_ID: sec:mutation-testing
:END:

#+begin_src python
"""
Mutation testing: test the tests themselves
Concept: introduce bugs to see if tests catch them
"""

def demonstrate_mutation_testing():
    """
    Mutation testing validates test suite effectiveness.

    Process:
    1. Mutate code (introduce bugs)
    2. Run tests
    3. Check if tests fail (they should!)

    Common mutations:
    - Change operators: + to -, * to /
    - Change constants: 0.5 to 0.6
    - Remove lines
    - Change comparison operators

    Tools:
    - mutmut: Python mutation testing
    - cosmic-ray: Another mutation testing tool
    """
    print("Mutation Testing Concepts")
    print("=" * 60)
    print("\nExample mutations to test:")
    print("  Original: E_n = HBAR * omega * (n + 0.5)")
    print("  Mutant 1: E_n = HBAR * omega * (n + 0.6)  # Change constant")
    print("  Mutant 2: E_n = HBAR * omega * (n - 0.5)  # Change operator")
    print("  Mutant 3: E_n = HBAR * omega * n          # Remove term")
    print("\nA good test suite should catch ALL these mutations!")
    print("\nTo run mutation testing:")
    print("  pip install mutmut")
    print("  mutmut run --paths-to-mutate=qho_toolkit.py")
    print("  mutmut results")
    print("\nGoal: >80% mutation score (80% of mutations caught)")

demonstrate_mutation_testing()
#+end_src

* Part III: Numerical Methods with Comprehensive Testing
:PROPERTIES:
:CUSTOM_ID: sec:numerical-methods-testing
:END:

** Validated Numerical Integration and ODEs
:PROPERTIES:
:CUSTOM_ID: sec:validated-integration
:END:

#+begin_src python
"""
Numerical integration with validation and error estimation
"""

from scipy import integrate

class ValidatedIntegration:
    """Integration methods with comprehensive error checking"""

    @staticmethod
    def adaptive_quadrature(
        func: Callable,
        a: float,
        b: float,
        tol: float = 1e-8,
        max_subdivisions: int = 50
    ) -> Tuple[float, float, Dict]:
        """
        Adaptive quadrature with error estimation.

        Returns:
            result: Integral value
            error: Estimated error
            info: Diagnostic information
        """
        result, error = integrate.quad(
            func, a, b,
            epsabs=tol,
            epsrel=tol,
            limit=max_subdivisions
        )

        info = {
            'method': 'adaptive_quadrature',
            'tolerance': tol,
            'estimated_error': error,
            'converged': error < tol
        }

        if not info['converged']:
            logger.warning(
                f"Integration may not have converged: error={error:.2e}"
            )

        return result, error, info

    @staticmethod
    def test_integration_accuracy():
        """Test integration on known problems"""
        # Test 1: Simple polynomial
        def f1(x):
            return x**2

        result, error, _ = ValidatedIntegration.adaptive_quadrature(
            f1, 0, 1
        )
        expected = 1/3
        assert np.isclose(result, expected, atol=1e-10), \
            f"‚à´x¬≤ dx failed: {result} vs {expected}"

        # Test 2: Exponential
        def f2(x):
            return np.exp(-x)

        result, error, _ = ValidatedIntegration.adaptive_quadrature(
            f2, 0, np.inf
        )
        expected = 1.0
        assert np.isclose(result, expected, atol=1e-8), \
            f"‚à´e^(-x) dx failed: {result} vs {expected}"

        logger.info("‚úì Integration validation passed")

# Run validation
ValidatedIntegration.test_integration_accuracy()
#+end_src

** Time Evolution with Error Control
:PROPERTIES:
:CUSTOM_ID: sec:time-evolution-validation
:END:

#+begin_src python :tangle qho_toolkit.py
"""
Time evolution with comprehensive error checking and validation
"""

class ValidatedTimePropagator:
    """Base class for time propagators with validation"""

    def __init__(self, system: QuantumSystem, dt: float):
        self.system = system
        self.dt = dt
        self._validate_timestep()

    def _validate_timestep(self):
        """Validate time step is appropriate"""
        # Estimate maximum frequency
        omega_max = np.sqrt(
            2 * np.max(self.system.potential(self.system.x_grid)) /
            self.system.mass
        )

        # Nyquist criterion
        dt_max = np.pi / omega_max if omega_max > 0 else np.inf

        if self.dt > dt_max:
            logger.warning(
                f"Time step dt={self.dt:.4f} may be too large. "
                f"Consider dt < {dt_max:.4f}"
            )

    def validate_evolution(
        self,
        psi_initial: np.ndarray,
        psi_final: np.ndarray
    ) -> Dict[str, bool]:
        """
        Validate time evolution preserves quantum properties.

        Returns:
            Dictionary of validation results
        """
        results = {}

        # Check norm conservation
        norm_initial = np.trapz(
            np.abs(psi_initial)**2,
            self.system.x_grid
        )
        norm_final = np.trapz(
            np.abs(psi_final)**2,
            self.system.x_grid
        )

        results['norm_conserved'] = np.isclose(
            norm_initial, norm_final,
            rtol=1e-6
        )

        if not results['norm_conserved']:
            logger.warning(
                f"Norm not conserved: {norm_initial:.6f} ‚Üí {norm_final:.6f}"
            )

        # Check energy conservation (for time-independent Hamiltonian)
        H = self.system.get_hamiltonian_matrix()

        E_initial = np.vdot(psi_initial, H @ psi_initial).real * self.system.dx
        E_final = np.vdot(psi_final, H @ psi_final).real * self.system.dx

        results['energy_conserved'] = np.isclose(
            E_initial, E_final,
            rtol=1e-4
        )

        if not results['energy_conserved']:
            logger.warning(
                f"Energy not conserved: {E_initial:.6f} ‚Üí {E_final:.6f}"
            )

        return results

class SplitStepPropagator(ValidatedTimePropagator):
    """
    Split-step Fourier method with validation.
    """

    def __init__(self, system: QuantumSystem, dt: float):
        super().__init__(system, dt)
        self.x_grid = system.x_grid
        self.dx = system.dx

        # Momentum grid
        N = len(self.x_grid)
        self.k_grid = 2 * np.pi * np.fft.fftfreq(N, self.dx)

        # Precompute exponentials
        V = system.potential(self.x_grid)
        self.exp_V_half = np.exp(-1j * V * self.dt / (2 * HBAR))

        T_k = HBAR**2 * self.k_grid**2 / (2 * system.mass)
        self.exp_T = np.exp(-1j * T_k * self.dt / HBAR)

    def step(self, psi: np.ndarray) -> np.ndarray:
        """Evolve wavefunction by one time step"""
        # V/2
        psi = self.exp_V_half * psi

        # FFT to momentum space
        psi_k = np.fft.fft(psi)

        # Apply kinetic operator
        psi_k = self.exp_T * psi_k

        # IFFT back
        psi = np.fft.ifft(psi_k)

        # V/2
        psi = self.exp_V_half * psi

        return psi

    def evolve(
        self,
        psi_0: np.ndarray,
        t_max: float,
        validate_interval: int = 100
    ) -> Tuple[np.ndarray, np.ndarray, List[Dict]]:
        """
        Evolve with periodic validation.

        Returns:
            times: Time array
            psi_t: Wavefunction evolution
            validation_results: List of validation results
        """
        n_steps = int(t_max / self.dt)
        times = np.linspace(0, t_max, n_steps)

        psi_t = np.zeros((n_steps, len(self.x_grid)), dtype=complex)
        psi_t[0] = psi_0

        validation_results = []
        psi = psi_0.copy()

        for i in range(1, n_steps):
            psi = self.step(psi)
            psi_t[i] = psi

            # Periodic validation
            if i % validate_interval == 0:
                validation = self.validate_evolution(psi_0, psi)
                validation['step'] = i
                validation['time'] = times[i]
                validation_results.append(validation)

                if not all(validation.values()):
                    logger.warning(f"Validation failed at step {i}")

        return times, psi_t, validation_results

logger.info("Validated time propagator defined")
#+end_src

** Testing Time Evolution
:PROPERTIES:
:CUSTOM_ID: sec:test-time-evolution
:END:

#+begin_src python
"""
Comprehensive tests for time evolution
"""

class TestTimeEvolution:
    """Test suite for time propagation methods"""

    @pytest.fixture
    def simple_gaussian(self, qho):
        """Fixture: Gaussian wave packet"""
        x0 = 0.0
        sigma = 1.0 / np.sqrt(2 * qho.alpha)
        psi = np.exp(-(qho.x_grid - x0)**2 / (2*sigma**2))
        norm = np.sqrt(np.trapz(np.abs(psi)**2, qho.x_grid))
        return psi / norm

    def test_stationary_state_evolution(self, qho):
        """Test that stationary states don't evolve (except phase)"""
        # Use ground state
        psi_0 = qho.analytical_wavefunction(qho.x_grid, 0)

        # Evolve for short time
        propagator = SplitStepPropagator(qho, dt=0.01)
        times, psi_t, _ = propagator.evolve(psi_0, t_max=1.0)

        # Probability distribution shouldn't change
        prob_initial = np.abs(psi_0)**2
        prob_final = np.abs(psi_t[-1])**2

        max_diff = np.max(np.abs(prob_initial - prob_final))
        assert max_diff < 1e-6, \
            f"Stationary state evolved: max diff = {max_diff}"

    def test_norm_conservation_long_evolution(self, qho, simple_gaussian):
        """Test norm conservation over long time"""
        propagator = SplitStepPropagator(qho, dt=0.01)
        times, psi_t, validations = propagator.evolve(
            simple_gaussian,
            t_max=10.0,
            validate_interval=50
        )

        # Check all validations passed
        for val in validations:
            assert val['norm_conserved'], \
                f"Norm not conserved at t={val['time']:.2f}"

    def test_energy_conservation(self, qho, simple_gaussian):
        """Test energy conservation for time-independent Hamiltonian"""
        propagator = SplitStepPropagator(qho, dt=0.01)
        H = qho.get_hamiltonian_matrix()

        # Initial energy
        E_0 = np.vdot(simple_gaussian, H @ simple_gaussian).real * qho.dx

        # Evolve
        times, psi_t, _ = propagator.evolve(simple_gaussian, t_max=5.0)

        # Check energy at several times
        for i in [len(times)//4, len(times)//2, 3*len(times)//4, -1]:
            psi = psi_t[i]
            E_t = np.vdot(psi, H @ psi).real * qho.dx
            rel_error = abs(E_t - E_0) / abs(E_0)
            assert rel_error < 1e-3, \
                f"Energy not conserved at t={times[i]:.2f}: " \
                f"rel_error={rel_error:.2e}"

    def test_time_reversal_symmetry(self, qho, simple_gaussian):
        """Test time reversal symmetry"""
        propagator_forward = SplitStepPropagator(qho, dt=0.01)
        propagator_backward = SplitStepPropagator(qho, dt=-0.01)

        # Forward evolution
        psi_forward = simple_gaussian.copy()
        for _ in range(100):
            psi_forward = propagator_forward.step(psi_forward)

        # Backward evolution
        psi_backward = psi_forward.copy()
        for _ in range(100):
            psi_backward = propagator_backward.step(psi_backward)

        # Should return to initial state
        overlap = np.abs(np.trapz(
            psi_backward.conj() * simple_gaussian,
            qho.x_grid
        ))

        assert overlap > 0.99, \
            f"Time reversal failed: overlap = {overlap:.4f}"

logger.info("Time evolution tests defined")
#+end_src

* Part IV: Machine Learning with Test-Driven Development
:PROPERTIES:
:CUSTOM_ID: sec:ml-tdd
:END:

** Physics-Informed Neural Networks with Validation
:PROPERTIES:
:CUSTOM_ID: sec:pinn-validation
:END:

#+begin_src python
"""
Physics-Informed Neural Networks with comprehensive testing
"""

import torch
import torch.nn as nn
import torch.optim as optim

torch.manual_seed(42)

class ValidatedQuantumNeuralNetwork(nn.Module):
    """
    Neural network with built-in validation for quantum mechanics.
    """

    def __init__(self, hidden_layers: List[int] = [64, 64, 64]):
        super().__init__()

        layers = []
        input_size = 1

        for hidden_size in hidden_layers:
            layers.append(nn.Linear(input_size, hidden_size))
            layers.append(nn.Tanh())
            input_size = hidden_size

        # Output: real part only (ground state is real)
        layers.append(nn.Linear(input_size, 1))

        self.network = nn.Sequential(*layers)
        self._initialize_weights()

    def _initialize_weights(self):
        """Initialize weights with Xavier initialization"""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_normal_(m.weight)
                nn.init.zeros_(m.bias)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.network(x)

    def count_parameters(self) -> int:
        """Count trainable parameters"""
        return sum(p.numel() for p in self.parameters() if p.requires_grad)

class TestablePINNSolver:
    """
    PINN solver with comprehensive testing and validation.
    """

    def __init__(
        self,
        potential_func: Callable,
        x_domain: Tuple[float, float],
        mass: float = MASS,
        device: str = 'cpu'
    ):
        self.potential_func = potential_func
        self.x_min, self.x_max = x_domain
        self.mass = mass
        self.device = device

        self.network = ValidatedQuantumNeuralNetwork().to(device)
        self.energy = nn.Parameter(torch.tensor([0.5], device=device))

        # Loss weights
        self.lambda_bc = 100.0
        self.lambda_norm = 10.0

        # Training history for analysis
        self.history = {
            'loss': [],
            'loss_pde': [],
            'loss_bc': [],
            'loss_norm': [],
            'energy': []
        }

    def compute_pde_loss(self, x: torch.Tensor) -> torch.Tensor:
        """Compute PDE residual with validation"""
        x.requires_grad_(True)

        psi = self.network(x)

        # Derivatives
        psi_x = torch.autograd.grad(
            psi, x, torch.ones_like(psi),
            create_graph=True
        )[0]

        psi_xx = torch.autograd.grad(
            psi_x, x, torch.ones_like(psi_x),
            create_graph=True
        )[0]

        # Hamiltonian
        T_psi = -HBAR**2 / (2 * self.mass) * psi_xx
        V = self.potential_func(x.detach().cpu().numpy())
        V = torch.tensor(V, dtype=torch.float32, device=self.device).reshape(-1, 1)
        V_psi = V * psi
        H_psi = T_psi + V_psi

        E_psi = self.energy * psi

        residual = H_psi - E_psi

        return torch.mean(residual**2)

    def compute_boundary_loss(self, x_boundary: torch.Tensor) -> torch.Tensor:
        """Boundary condition loss"""
        psi = self.network(x_boundary)
        return torch.mean(psi**2)

    def compute_normalization_loss(self, x: torch.Tensor, dx: float) -> torch.Tensor:
        """Normalization loss"""
        psi = self.network(x)
        norm = torch.trapz(psi**2, x.squeeze(), dim=0)
        return (norm - 1.0)**2

    def train(
        self,
        n_epochs: int = 5000,
        n_points: int = 256,
        lr: float = 0.001,
        verbose: int = 500,
        early_stopping: bool = True,
        patience: int = 100
    ):
        """
        Train with early stopping and validation.
        """
        optimizer = optim.Adam(
            list(self.network.parameters()) + [self.energy],
            lr=lr
        )

        x_train = torch.linspace(
            self.x_min, self.x_max, n_points,
            device=self.device
        ).reshape(-1, 1)
        dx = (self.x_max - self.x_min) / n_points

        x_boundary = torch.tensor(
            [[self.x_min], [self.x_max]],
            dtype=torch.float32,
            device=self.device
        )

        best_loss = float('inf')
        patience_counter = 0

        for epoch in range(n_epochs):
            optimizer.zero_grad()

            loss_pde = self.compute_pde_loss(x_train)
            loss_bc = self.compute_boundary_loss(x_boundary)
            loss_norm = self.compute_normalization_loss(x_train, dx)

            loss = loss_pde + self.lambda_bc * loss_bc + \
                   self.lambda_norm * loss_norm

            loss.backward()
            optimizer.step()

            # Record history
            self.history['loss'].append(loss.item())
            self.history['loss_pde'].append(loss_pde.item())
            self.history['loss_bc'].append(loss_bc.item())
            self.history['loss_norm'].append(loss_norm.item())
            self.history['energy'].append(self.energy.item())

            # Early stopping
            if early_stopping:
                if loss.item() < best_loss:
                    best_loss = loss.item()
                    patience_counter = 0
                else:
                    patience_counter += 1

                if patience_counter >= patience:
                    logger.info(f"Early stopping at epoch {epoch+1}")
                    break

            if (epoch + 1) % verbose == 0 or epoch == 0:
                logger.info(
                    f"Epoch {epoch+1}/{n_epochs}: "
                    f"Loss={loss.item():.6f}, E={self.energy.item():.6f}"
                )

        return self.history

    def predict(self, x: np.ndarray) -> np.ndarray:
        """Get normalized wavefunction prediction"""
        self.network.eval()
        with torch.no_grad():
            x_tensor = torch.tensor(
                x, dtype=torch.float32, device=self.device
            ).reshape(-1, 1)
            psi = self.network(x_tensor).cpu().numpy().flatten()

        # Normalize
        norm = np.sqrt(np.trapz(psi**2, x))
        return psi / norm

class TestPINN:
    """Test suite for Physics-Informed Neural Networks"""

    def test_pinn_architecture(self):
        """Test PINN network architecture"""
        network = ValidatedQuantumNeuralNetwork([32, 32])

        # Test forward pass
        x = torch.randn(10, 1)
        output = network(x)

        assert output.shape == (10, 1)
        assert not torch.isnan(output).any()
        assert not torch.isinf(output).any()

    def test_pinn_gradients(self):
        """Test that gradients flow correctly"""
        network = ValidatedQuantumNeuralNetwork()
        x = torch.randn(5, 1, requires_grad=True)

        output = network(x)
        output.sum().backward()

        # Check gradients exist
        assert x.grad is not None
        for param in network.parameters():
            assert param.grad is not None

    def test_pinn_convergence_simple(self):
        """Test PINN converges for simple harmonic oscillator"""
        qho = QuantumHarmonicOscillator()
        pinn = TestablePINNSolver(qho.potential, (-6, 6))

        # Train
        history = pinn.train(n_epochs=1000, n_points=128, verbose=10000)

        # Check convergence
        final_loss = history['loss'][-1]
        assert final_loss < 0.01, f"PINN didn't converge: loss={final_loss}"

        # Check energy accuracy
        E_pinn = pinn.energy.item()
        E_exact = qho.analytical_energy(0)
        rel_error = abs(E_pinn - E_exact) / E_exact

        assert rel_error < 0.05, \
            f"Energy error too large: {rel_error:.2%}"

    def test_pinn_wavefunction_properties(self):
        """Test PINN wavefunction satisfies quantum properties"""
        qho = QuantumHarmonicOscillator()
        pinn = TestablePINNSolver(qho.potential, (-6, 6))
        pinn.train(n_epochs=500, verbose=10000)

        x_test = np.linspace(-6, 6, 200)
        psi_pinn = pinn.predict(x_test)

        # Test normalization
        norm = np.trapz(psi_pinn**2, x_test)
        assert np.isclose(norm, 1.0, rtol=1e-2)

        # Test symmetry (ground state should be even)
        psi_left = psi_pinn[x_test < 0]
        psi_right = psi_pinn[x_test > 0][::-1]
        symmetry_error = np.mean(np.abs(psi_left - psi_right))
        assert symmetry_error < 0.1

logger.info("PINN testing framework defined")
#+end_src

* Part V: Complete Capstone with Test-Driven Development
:PROPERTIES:
:CUSTOM_ID: sec:capstone-tdd
:END:

** Double-Well Potential with Comprehensive Testing
:PROPERTIES:
:CUSTOM_ID: sec:double-well-tdd
:END:

#+begin_src python :tangle qho_toolkit.py
"""
Double-well potential with full test coverage
"""

class DoubleWellPotential(QuantumSystem):
    """
    Double-well: V(x) = Œª(x¬≤ - a¬≤)¬≤

    Includes validation and testing utilities.
    """

    def __init__(
        self,
        a: float = 2.0,
        lambda_param: float = 0.1,
        mass: float = MASS,
        x_grid: Optional[np.ndarray] = None
    ):
        super().__init__(mass, x_grid)
        self.a = a
        self.lambda_param = lambda_param

        # Validation
        if a <= 0:
            raise ValueError(f"Well separation must be positive: a={a}")
        if lambda_param <= 0:
            raise ValueError(f"Barrier strength must be positive: Œª={lambda_param}")

    def potential(self, x: np.ndarray) -> np.ndarray:
        """Double-well potential"""
        return self.lambda_param * (x**2 - self.a**2)**2

    def barrier_height(self) -> float:
        """Calculate barrier height at x=0"""
        return self.potential(np.array([0.0]))[0]

    def well_minima(self) -> Tuple[float, float]:
        """Return positions of well minima"""
        return (-self.a, self.a)

    def analytical_energy(self, n: int) -> float:
        """No simple closed form - use numerical"""
        raise NotImplementedError(
            "Use numerical solve_eigenvalue_problem()"
        )

    def analytical_wavefunction(self, x: np.ndarray, n: int) -> np.ndarray:
        """No simple closed form - use numerical"""
        raise NotImplementedError(
            "Use numerical solve_eigenvalue_problem()"
        )

class TestDoubleWell:
    """Test suite for double-well potential"""

    def test_potential_shape(self):
        """Test potential has correct shape"""
        dw = DoubleWellPotential(a=2.0, lambda_param=0.1)
        x = np.linspace(-5, 5, 100)
        V = dw.potential(x)

        # Should have minima at ¬±a
        minima_indices = np.where(
            (V[1:-1] < V[:-2]) & (V[1:-1] < V[2:])
        )[0] + 1

        assert len(minima_indices) == 2, "Should have exactly 2 minima"

        # Check positions approximately at ¬±a
        x_minima = x[minima_indices]
        assert np.abs(x_minima[0] + dw.a) < 0.5
        assert np.abs(x_minima[1] - dw.a) < 0.5

    def test_barrier_height(self):
        """Test barrier height calculation"""
        lambda_param = 0.1
        a = 2.0
        dw = DoubleWellPotential(a=a, lambda_param=lambda_param)

        barrier = dw.barrier_height()
        expected = lambda_param * a**4

        assert np.isclose(barrier, expected, rtol=1e-10)

    def test_tunneling_splitting(self):
        """Test tunneling splitting between ground states"""
        dw = DoubleWellPotential(a=2.0, lambda_param=0.1)
        energies, wavefunctions = dw.solve_eigenvalue_problem(n_states=10)

        # First two states should be split by tunneling
        E0, E1 = energies[0], energies[1]
        splitting = E1 - E0

        # Splitting should be positive and small
        assert splitting > 0
        assert splitting < E0  # Much smaller than ground energy

        logger.info(f"Tunneling splitting: ŒîE = {splitting:.6f}")

    def test_wavefunction_symmetry(self):
        """Test symmetric/antisymmetric wavefunctions"""
        dw = DoubleWellPotential(a=2.0, lambda_param=0.1)
        _, wavefunctions = dw.solve_eigenvalue_problem(n_states=2)

        psi_0, psi_1 = wavefunctions[0], wavefunctions[1]

        # Test symmetry under x ‚Üí -x
        x_grid = dw.x_grid
        psi_0_reflected = np.flip(psi_0)
        psi_1_reflected = np.flip(psi_1)

        # Ground state should be symmetric
        symmetric_error_0 = np.mean(np.abs(psi_0 - psi_0_reflected))
        assert symmetric_error_0 < 0.1, f"œà_0 not symmetric: {symmetric_error_0}"

        # First excited should be antisymmetric
        antisymmetric_error_1 = np.mean(np.abs(psi_1 + psi_1_reflected))
        assert antisymmetric_error_1 < 0.1, f"œà_1 not antisymmetric"

logger.info("Double-well with tests defined")
#+end_src

** Complete Test Report Generator
:PROPERTIES:
:CUSTOM_ID: sec:test-reporting
:END:

#+begin_src python
"""
Automated test reporting and documentation
"""

class TestReportGenerator:
    """Generate comprehensive test reports"""

    def __init__(self, output_dir: str = "./test_reports"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)

    def generate_coverage_report(self):
        """Generate HTML coverage report"""
        report_path = self.output_dir / "coverage"

        print(f"Coverage Report Generator")
        print("=" * 60)
        print(f"\nTo generate coverage report:")
        print(f"  pytest --cov=qho_toolkit \\")
        print(f"         --cov-report=html:{report_path} \\")
        print(f"         --cov-report=term-missing")
        print(f"\nReport will be saved to: {report_path}/index.html")

    def generate_test_summary(self, test_results: Dict) -> str:
        """Generate markdown test summary"""
        summary = ["# Test Summary Report\n"]
        summary.append(f"Generated: {pd.Timestamp.now()}\n\n")

        summary.append("## Test Statistics\n\n")
        summary.append(f"- Total tests: {test_results.get('total', 0)}\n")
        summary.append(f"- Passed: {test_results.get('passed', 0)}\n")
        summary.append(f"- Failed: {test_results.get('failed', 0)}\n")
        summary.append(f"- Skipped: {test_results.get('skipped', 0)}\n\n")

        if test_results.get('failed', 0) > 0:
            summary.append("## ‚ö†Ô∏è Failed Tests\n\n")
            for failure in test_results.get('failures', []):
                summary.append(f"- {failure}\n")

        summary.append("\n## Coverage\n\n")
        summary.append(f"- Statement coverage: {test_results.get('coverage', 0):.1f}%\n")

        return "".join(summary)

    def save_report(self, content: str, filename: str = "test_summary.md"):
        """Save report to file"""
        file_path = self.output_dir / filename
        with open(file_path, 'w') as f:
            f.write(content)
        logger.info(f"Report saved: {file_path}")

# Example usage
reporter = TestReportGenerator()
reporter.generate_coverage_report()

example_results = {
    'total': 50,
    'passed': 48,
    'failed': 2,
    'skipped': 0,
    'coverage': 92.5,
    'failures': ['test_extreme_case', 'test_edge_condition']
}

summary = reporter.generate_test_summary(example_results)
print("\n" + summary)
#+end_src

* Best Practices and Conclusions
:PROPERTIES:
:CUSTOM_ID: sec:best-practices-final
:END:

** Complete Testing Checklist
:PROPERTIES:
:CUSTOM_ID: sec:testing-checklist
:END:

#+begin_src python
"""
Comprehensive testing checklist for computational physics
"""

def print_testing_checklist():
    """Display testing best practices checklist"""

    checklist = """
COMPREHENSIVE TESTING CHECKLIST FOR COMPUTATIONAL PHYSICS
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚ñ° UNIT TESTS
  ‚úì Test individual functions in isolation
  ‚úì Test edge cases (n=0, negative values, infinity)
  ‚úì Test error handling and exceptions
  ‚úì Test with known analytical solutions
  ‚úì Use parametrized tests for multiple inputs
  Target: >90% code coverage

‚ñ° INTEGRATION TESTS
  ‚úì Test complete workflows
  ‚úì Test interaction between components
  ‚úì Test data flow through system
  ‚úì Test with realistic problem sizes

‚ñ° PROPERTY-BASED TESTS
  ‚úì Test mathematical properties (symmetry, orthogonality)
  ‚úì Use hypothesis for random test generation
  ‚úì Test physical conservation laws
  ‚úì Test numerical stability

‚ñ° REGRESSION TESTS
  ‚úì Save reference data for validation
  ‚úì Test against previous versions
  ‚úì Prevent breaking changes
  ‚úì Track performance over time

‚ñ° PERFORMANCE TESTS
  ‚úì Benchmark critical code paths
  ‚úì Test scalability with problem size
  ‚úì Profile for bottlenecks
  ‚úì Set performance baselines

‚ñ° VALIDATION TESTS
  ‚úì Compare numerical vs analytical solutions
  ‚úì Test convergence with grid refinement
  ‚úì Validate against published results
  ‚úì Cross-validate with other codes

‚ñ° CONTINUOUS INTEGRATION
  ‚úì Run tests on every commit
  ‚úì Test on multiple platforms/Python versions
  ‚úì Automated coverage reporting
  ‚úì Fail fast on test failures

‚ñ° DOCUMENTATION TESTS
  ‚úì Test code examples in docstrings
  ‚úì Verify documentation matches code
  ‚úì Test README examples
  ‚úì Keep docs in sync with tests

‚ñ° CODE QUALITY
  ‚úì Use type hints and mypy
  ‚úì Follow PEP 8 style guide
  ‚úì Use linters (pylint, flake8, ruff)
  ‚úì Format with black
  ‚úì Write clear docstrings

‚ñ° REPRODUCIBILITY
  ‚úì Pin dependency versions
  ‚úì Set random seeds
  ‚úì Document environment setup
  ‚úì Use containerization (Docker)
  ‚úì Version control everything
"""

    print(checklist)

    print("\nTESTING TOOLS ECOSYSTEM")
    print("‚îÄ" * 60)

    tools = {
        "Test Framework": "pytest",
        "Coverage": "coverage.py / pytest-cov",
        "Property Testing": "hypothesis",
        "Performance": "pytest-benchmark",
        "Mutation Testing": "mutmut",
        "Type Checking": "mypy / pyright",
        "Linting": "ruff / pylint / flake8",
        "Formatting": "black / ruff format",
        "CI/CD": "GitHub Actions / GitLab CI",
        "Documentation": "sphinx / mkdocs"
    }

    for category, tool in tools.items():
        print(f"  {category:20} ‚Üí {tool}")

    print("\n" + "=" * 60)

print_testing_checklist()
#+end_src

** Summary and Next Steps
:PROPERTIES:
:CUSTOM_ID: sec:final-summary
:END:

#+begin_src python
"""
Final summary: What we've accomplished
"""

def print_masterclass_summary():
    """Print comprehensive summary"""

    print("\n")
    print("=" * 70)
    print(" " * 10 + "QUANTUM HARMONIC OSCILLATOR MASTERCLASS")
    print(" " * 5 + "WITH COMPREHENSIVE TESTING & QUALITY ASSURANCE")
    print("=" * 70)

    print("\nüìö WHAT YOU'VE MASTERED:\n")

    achievements = {
        "Part I: Python Ecosystem with TDD": [
            "Environment setup with testing infrastructure",
            "Custom exceptions with validation decorators",
            "OOP design with abstract base classes",
            "Unit testing with pytest",
            "Property-based testing with hypothesis",
            "Test fixtures and parametrization"
        ],
        "Part II: Advanced Testing": [
            "Regression testing framework",
            "Data-driven testing",
            "Mutation testing concepts",
            "Performance benchmarking",
            "Code profiling and optimization",
            "Test coverage measurement (>90%)"
        ],
        "Part III: Numerical Methods with Validation": [
            "Validated numerical integration",
            "Error-controlled time evolution",
            "Norm and energy conservation tests",
            "Convergence analysis",
            "Grid independence verification",
            "Time-reversal symmetry tests"
        ],
        "Part IV: ML with Testing": [
            "Physics-Informed Neural Networks",
            "PINN architecture validation",
            "Training convergence tests",
            "Wavefunction property verification",
            "Early stopping and regularization",
            "Model performance evaluation"
        ],
        "Part V: Production-Ready Code": [
            "Complete double-well implementation",
            "Comprehensive test suites",
            "Integration testing",
            "Automated reporting",
            "CI/CD best practices",
            "Documentation testing"
        ]
    }

    for section, items in achievements.items():
        print(f"\n{section}")
        print("-" * 70)
        for item in items:
            print(f"  ‚úì {item}")

    print("\n" + "=" * 70)
    print("\nüéØ KEY METRICS ACHIEVED:\n")

    metrics = [
        ("Test Coverage", ">90%", "Statement, branch, function"),
        ("Test Count", "50+", "Unit, integration, property-based"),
        ("Documentation", "Complete", "Docstrings, examples, tutorials"),
        ("Code Quality", "A+", "Type hints, linting, formatting"),
        ("Validation", "Comprehensive", "Physical, numerical, statistical"),
        ("Reproducibility", "100%", "Fixed seeds, pinned dependencies"),
        ("CI/CD", "Automated", "Multi-platform, multi-version"),
        ("Performance", "Optimized", "Profiled, benchmarked")
    ]

    for metric, value, notes in metrics:
        print(f"  {metric:20} ‚Üí {value:15} ({notes})")

    print("\n" + "=" * 70)
    print("\nüöÄ NEXT STEPS FOR ADVANCED LEARNING:\n")

    next_steps = [
        "1. Extend to higher dimensions (2D/3D quantum systems)",
        "2. Implement many-body quantum mechanics",
        "3. Add GPU acceleration with CuPy/JAX",
        "4. Integrate with quantum chemistry packages",
        "5. Implement advanced ML (transformers, GNNs)",
        "6. Contribute to open-source projects (QuTiP, PySCF)",
        "7. Publish reproducible research papers",
        "8. Deploy production systems with FastAPI/Docker"
    ]

    for step in next_steps:
        print(f"  {step}")

    print("\n" + "=" * 70)
    print("\nüí° PROFESSIONAL DEVELOPMENT:\n")

    skills = [
        "‚úì Write production-quality scientific code",
        "‚úì Implement comprehensive test suites",
        "‚úì Validate numerical methods rigorously",
        "‚úì Apply ML to physics problems",
        "‚úì Use modern software engineering practices",
        "‚úì Collaborate using Git/GitHub workflows",
        "‚úì Document and share reproducible research",
        "‚úì Optimize code for performance"
    ]

    for skill in skills:
        print(f"  {skill}")

    print("\n" + "=" * 70)
    print("\nüìñ RECOMMENDED RESOURCES:\n")

    resources = {
        "Books": [
            "- 'Computational Physics' by Newman",
            "- 'Modern Quantum Mechanics' by Sakurai",
            "- 'Python Testing with pytest' by Okken"
        ],
        "Online": [
            "- pytest documentation (docs.pytest.org)",
            "- Hypothesis documentation (hypothesis.readthedocs.io)",
            "- SciPy testing guide",
            "- ArXiv.org for latest research"
        ],
        "Practice": [
            "- Contribute to SciPy/NumPy",
            "- Join computational physics communities",
            "- Participate in code review",
            "- Mentor others in testing practices"
        ]
    }

    for category, items in resources.items():
        print(f"\n{category}:")
        for item in items:
            print(f"  {item}")

    print("\n" + "=" * 70)
    print("\nüéì CERTIFICATE OF COMPLETION:\n")
    print("  You have successfully completed:")
    print("  ‚Ä¢ Quantum Harmonic Oscillator Masterclass")
    print("  ‚Ä¢ Test-Driven Development for Scientific Computing")
    print("  ‚Ä¢ Production-Quality Code Practices")
    print("\n  You are now equipped to:")
    print("  ‚úì Write reliable, tested scientific software")
    print("  ‚úì Implement state-of-the-art numerical methods")
    print("  ‚úì Apply machine learning to physics problems")
    print("  ‚úì Lead computational physics projects")

    print("\n" + "=" * 70)
    print("\nüôè THANK YOU FOR YOUR DEDICATION!")
    print("\n  Keep computing, keep testing, keep learning!")
    print("\n" + "=" * 70 + "\n")

print_masterclass_summary()
#+end_src

* Appendix: Complete Test Suite Runner
:PROPERTIES:
:CUSTOM_ID: sec:appendix
:END:

** Running All Tests

#+begin_src python
"""
Master test runner script
"""

def run_complete_test_suite():
    """
    Run complete test suite with all options.

    This script demonstrates how to run the full test battery.
    """

    test_commands = """
COMPLETE TEST SUITE EXECUTION GUIDE
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

1. BASIC TEST RUN
   pytest test_qho.py -v

2. WITH COVERAGE
   pytest --cov=qho_toolkit --cov-report=html --cov-report=term-missing

3. WITH MARKERS
   pytest -m "not slow"              # Skip slow tests
   pytest -m "unit"                  # Run only unit tests
   pytest -m "integration"           # Run integration tests

4. PARALLEL EXECUTION
   pytest -n auto                    # Use all CPU cores
   pytest -n 4                       # Use 4 workers

5. WITH BENCHMARKS
   pytest --benchmark-only           # Run only benchmarks
   pytest --benchmark-compare        # Compare with previous

6. PROPERTY-BASED TESTS
   pytest --hypothesis-show-statistics

7. VERBOSE OUTPUT
   pytest -vv --tb=short            # Verbose with short tracebacks
   pytest -vv --tb=long             # Full tracebacks

8. STOP ON FIRST FAILURE
   pytest -x                        # Stop on first failure
   pytest --maxfail=3               # Stop after 3 failures

9. RERUN FAILURES
   pytest --lf                      # Last failed
   pytest --ff                      # Failed first, then others

10. GENERATE REPORTS
    pytest --html=report.html       # HTML report
    pytest --junit-xml=junit.xml    # JUnit XML for CI

11. WITH TYPE CHECKING
    mypy qho_toolkit.py
    pytest --mypy

12. COMPLETE CI PIPELINE
    pytest --cov=qho_toolkit \\
           --cov-report=xml \\
           --cov-report=term \\
           --junit-xml=junit.xml \\
           --html=report.html \\
           -n auto \\
           -v

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
"""

    print(test_commands)

    print("\nQUICK START:")
    print("  # Install dependencies")
    print("  pip install pytest pytest-cov pytest-benchmark hypothesis pytest-xdist")
    print("\n  # Run basic tests")
    print("  pytest")
    print("\n  # Run with coverage")
    print("  pytest --cov=qho_toolkit")
    print("\n  # Generate full report")
    print("  pytest --cov=qho_toolkit --cov-report=html --html=test_report.html")

run_complete_test_suite()
#+end_src

** Configuration Files

#+begin_src python
"""
Generate configuration files for testing
"""

def generate_pytest_ini():
    """Generate pytest.ini configuration"""
    config = """
# pytest.ini
[pytest]
minversion = 7.0
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts =
    -ra
    --strict-markers
    --strict-config
    --cov=qho_toolkit
    --cov-report=term-missing:skip-covered
    --cov-report=html
    --cov-report=xml

markers =
    slow: marks tests as slow (deselect with '-m "not slow"')
    unit: unit tests
    integration: integration tests
    regression: regression tests
    performance: performance tests

[coverage:run]
source = qho_toolkit
omit =
    */tests/*
    */test_*.py
    */__pycache__/*

[coverage:report]
precision = 2
show_missing = True
skip_covered = False

[coverage:html]
directory = htmlcov
"""

    with open("pytest.ini", "w") as f:
        f.write(config)

    print("‚úì Generated: pytest.ini")

def generate_pyproject_toml():
    """Generate pyproject.toml for modern Python projects"""
    config = """
# pyproject.toml
[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "qho-toolkit"
version = "1.0.0"
description = "Quantum Harmonic Oscillator Computational Toolkit"
readme = "README.md"
requires-python = ">=3.10"
license = {text = "MIT"}
authors = [
    {name = "Your Name", email = "your.email@example.com"}
]
dependencies = [
    "numpy>=1.24.0",
    "scipy>=1.10.0",
    "matplotlib>=3.7.0",
    "pandas>=2.0.0",
    "torch>=2.0.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "pytest-benchmark>=4.0.0",
    "hypothesis>=6.82.0",
    "mypy>=1.4.0",
    "black>=23.0.0",
    "ruff>=0.0.280",
]

[tool.pytest.ini_options]
testpaths = ["tests"]
addopts = "--cov=qho_toolkit --cov-report=term-missing"

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true

[tool.black]
line-length = 88
target-version = ['py310', 'py311', 'py312']

[tool.ruff]
line-length = 88
select = ["E", "F", "I", "N", "W"]
ignore = []
"""

    with open("pyproject.toml", "w") as f:
        f.write(config)

    print("‚úì Generated: pyproject.toml")

# Generate configuration files
generate_pytest_ini()
generate_pyproject_toml()
print("\n‚úì All configuration files generated")
print("\nYou can now run:")
print("  pytest                    # Run all tests")
print("  pytest --cov             # With coverage")
print("  mypy qho_toolkit.py      # Type checking")
print("  black qho_toolkit.py     # Format code")
#+end_src

* Conclusion

This integrated masterclass combines cutting-edge computational physics with industrial-grade software engineering practices. You've learned to not only solve the Schr√∂dinger equation numerically but to do so with comprehensive testing, validation, and quality assurance that meets production standards.

The test-driven approach ensures your code is reliable, maintainable, and scientifically rigorous‚Äîessential qualities for modern computational research.

#+begin_quote
"Testing doesn't slow down development; it accelerates it by catching errors early and enabling confident refactoring."
‚Äî Modern Software Engineering Wisdom
#+end_quote

Good luck with your computational physics journey! üöÄ‚ú®

* Local Variables :noexport:

#+begin_src emacs-lisp :exports none :results silent
;; Ensure directories exist
(make-directory "./figures" t)
(make-directory "./test_data" t)
(make-directory "./test_reports" t)

;; Auto-refresh images
(add-hook 'org-babel-after-execute-hook 'org-redisplay-inline-images)

;; Org-babel configuration
(org-babel-do-load-languages
 'org-babel-load-languages
 '((python . t)
   (shell . t)))

(setq org-confirm-babel-evaluate nil)
#+end_src
